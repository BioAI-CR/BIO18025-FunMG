---
title: "Analysis of unmapped genomics reads and implication in genomic composition"
output: 
  html_notebook:
    code_folding: hide
    toc: yes
  BiocStyle::pdf_document:
    includes: null
    toc: no
  html_document:
    df_print: paged
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
options(digits=4)
library(data.table)
library(plyr)
library(reshape2)
library(data.table)
library(ggplot2)
apatheme = theme_bw()+
           theme(panel.grid.major=element_blank(),
                 panel.grid.minor=element_blank(),
                 panel.border=element_blank(),
                 axis.line=element_line())
library(futile.logger)
library(Rsamtools)
library(seqinr)

plotBars <- function(dd, cols=c('Assigned','Unassigned_NoFeatures','Unassigned_Unmapped'), xscale='Reads', 
                     ytext=2, id.vars='Timep') {
  bcol = c(id.vars,cols)
  ddt = melt.data.table(dd[,..bcol], id.vars=id.vars, value.name='Value', variable.name='ReadType')
  means = 0
  bcol = rev(cols)
  if(length(cols) > 1) means = colMeans(dd[,..bcol])
  lins = cumsum(means)
  gg = ggplot(data=ddt) + 
       geom_bar(aes_string(x=id.vars, y="Value", fill="ReadType"),
                stat='identity', width=1) + 
       geom_hline(yintercept=lins) +
       coord_flip() + ylab(xscale) +
       apatheme + theme(axis.text.y=element_text(size=ytext))
  return(gg)
}

```

```{r setupP}
projDir  = '/home/carlos/Projects/BIO18025-201808-FunMG-Kaiko/'
dataDir  = paste0(projDir, 'data/20191030-align-noconc/')
dataDir2 = paste0(projDir, 'data/20190522-QCData-rcg/mtg/')
dataDir3 = paste0(projDir, 'rcg/analysis/mtx_mtg/2.align-mtg-nomap/')
refsDir  = paste0(projDir, 'data/20190923-references/')
refsDir2 = paste0(projDir, 'rcg/analysis/mtx_mtg/references/')
genoDir  = paste0(projDir, 'rcg/genomes/')
infoDir1 = paste0(projDir, 'data/20190723-RemovedTPs/')
currDir  = getwd()
flog.info('Current working folder: %s', currDir)
stopifnot(dir.exists(dataDir3))
do.para = TRUE
if(do.para) {
  library(BiocParallel)
  bpp = MulticoreParam(workers=10, log=T, jobname='PP1', logdir=)
  register(BPPARAM=bpp)
}
```

## Purpose

This analysis attempts to identify species that have been missed in the construction of the individual genomic references.  It follows the same line of the analysis for transcriptomic data.  Genomic data is Paired End, and we need to do slight adjustments.

The overall scheme of the analysis is:

1. Use Global Genomic Reference (GGR) constructed for Tx data.
2. Align the genomic pairs unmapped concordantly in each timepoint against the GGR
3. Filter uniquely mapping pairs and extract identified genomic sequences (species)
4. Aggregate at individual level
5. For each individual, exclude from this list species already in the individual genomic reference
6. Do similar analysis on unmapped Gx reads and decide if individual genomic reference should be augmented and remapped in Gx and Tx.

In step 5, there should be little to no species known (we are using reads that did not map to begin with).  If there are known species --to the individual-- then, why ?

By a quick look at the nomap alignment stats a few timepoints (seem grouped by individual, e.g. all timepoints of individual are similar) have a large number of reads that are **unmapped** after this process.  
This suggests some species have not been identified yet and account for a large number of reads for the individual.

Mapper used is `Bowtie2`, under the assumption that splicing plays a minimal role.

## Alignment

```{r}
logfiles = list.files(path=dataDir, pattern='.*.log', full.names=T)
TPs = data.table(data.frame(logfile=logfiles, stringsAsFactors=F))
TPs[, tp := sapply(logfile, function(z) gsub('_align\\.log','',basename(z)))]
TPs[, sample := gsub('([A-Z0-9]+)-.*','\\1',tp)]

rmFile = paste0(infoDir1, 'remove-list.txt')
rmSampTP = readLines(rmFile)
rmSampTP = rmSampTP[-grep('^#',rmSampTP)]

flog.info('There are %d alignment log files, and %d timepoints/samples in the remove list', nrow(TPs), length(rmSampTP))

nn = unlist(sapply(rmSampTP, function(z) grep(z, make.names(TPs$tp))))
TPs = TPs[-nn,]
flog.info('After removing %d predefined dubious timepoints, %d timepoints remain (%d samples)', length(nn), nrow(TPs), length(unique(TPs$sample)))
```

```{r}
procLogFile <- function(ff) {
  ll = readLines(con=ff)
  nr = strtoi(unlist(strsplit(ll[grep('reads; of these:$',ll)],'[ ]+'))[1])
  su = strtoi(unlist(strsplit(ll[grep('aligned concordantly 0 times$',ll)],'[ ]+'))[2])
  s1 = strtoi(unlist(strsplit(ll[grep('aligned concordantly exactly 1 time$',ll)],'[ ]+'))[2])
  sm = strtoi(unlist(strsplit(ll[grep('aligned concordantly >1 times$',ll)],'[ ]+'))[2])
  return(list(PE.tot=nr, PE.uniq=s1, PE.mult=sm, PE.noconc=su, map.pe=(s1+sm)/(nr)))
}
TPs = cbind(TPs, rbindlist(llply(TPs$logfile, procLogFile)))
setcolorder(TPs, colnames(TPs)[-1])
TPs
```

This corresponds to the alignment of previously unmapped Tx reads, and columns here are:

  Column    | Description
  --------- + ----------------
  tp        | Timepoint ID
  sample    | Patient ID
  PE.tot    | Total originally unmapped pairs (Paired End)
  PE.uniq   | Number of uniquely mapping to global ref (PE)
  PE.mult   | Number of multiply mapping to global ref (PE)
  PE.noconc | Number of unmapped to global ref (PE)
  map.se    | Mapping efficiency $\frac{(PE_{uniq}+PE_{mult})}{PE_{tot}}$
  logfile   | Ditto


### Plot of the alignment stats per timepoint

```{r fig.width=8, fig.height=15}
plotBars(TPs, cols=c('PE.uniq','PE.mult','PE.noconc'), id.vars='tp')
```

```{r fig.width=8, fig.height=15}
ddk = copy(TPs)
for(cc in c('PE.uniq','PE.mult','PE.noconc')) { set(ddk, j=paste0(cc,'_pc'), value=ddk[, ..cc] / ddk$PE.tot) }
plotBars(ddk, cols=c('PE.uniq_pc','PE.mult_pc','PE.noconc_pc'), id.vars='tp')
```

### Summary by sample

```{r fig.width=8, fig.height=10}
ddj = ddk[, .(uniq=sum(PE.uniq_pc)/.N, multi=sum(PE.mult_pc)/.N, nomap=sum(PE.noconc_pc)/.N), by='sample']
setorder(ddj, nomap)
plotBars(ddj, cols=c('uniq','multi','nomap'), id.vars='sample', ytext=6)
```


We now plot the ratio of uniquely mapping reads in this global reference realignment to the total number of original uniquely mapping reads against the individual genomes. This should be a proxy of the missing species read fraction in the data.

```{r}
logfiles2 = list.files(path=dataDir2, pattern='.*.log', full.names=T)
TP2 = data.table(data.frame(logfile=logfiles2, stringsAsFactors=F))
TP2[, tp := sapply(logfile, function(z) gsub('_align\\.log','',basename(z)))]
TP2[, sample := gsub('([A-Z0-9]+)-.*','\\1',tp)]

flog.info('%d original alignment log files, and %d timepoints/samples in the remove list', nrow(TPs), length(rmSampTP))

nn = unlist(sapply(rmSampTP, function(z) grep(z, make.names(TP2$tp))))
TP2 = TP2[-nn,]
flog.info('After removing %d predefined dubious timepoints, %d timepoints remain (%d samples)', length(nn), nrow(TP2), length(unique(TP2$sample)))
```

In the combined table, columns are:

  Column    | Description
  --------- + ----------------
  tp        | sample-timepoint ID
  sample    | Patient ID
  PE.tot    | Total number of sequenced pairs (original, Paired End)
  PE.uniq   | Number of uniquely mapping to individual ref (PE)
  PE.mult   | Number of multiply mapping to individual ref (PE)
  PE.nomap  | Number of noconcordant to individual ref (PE)
  map.pe    | Mapping efficiency $\frac{(S_{uniq}+S_{mult})}{S_{tot}}$
  logfile   | Ditto
  i.PE.tot  | Total number of unmapped pairs global ref (Paired End)
  i.PE.uniq | Number of uniquely mapping to global ref (PE)
  i.PE.mult | Number of multiply mapping to global ref (PE)
  i.PE.nomap| Number of unmapped to global ref (PE)
  i.map.pe  | Mapping efficiency $\frac{(i.S_{uniq}+i.S_{mult})}{i.S_{tot}}$
  i.logfile | for the global ref alignment
  numfrac   | Ratio of newly uniquely mapped to original uniquely mapped $\frac{i.S_{uniq}}{S_{uniq}}$
  nmap.pe   | Combined new mapping efficiency $\frac{(S_{uniq}+S_{mult}+i.S_{uniq}+i.S_{mult})}{S_{tot}}$

```{r fig.width=8, fig.height=10}
TP2 = cbind(TP2, rbindlist(llply(TP2$logfile, procLogFile)))
setcolorder(TP2, colnames(TP2)[-1])
TP2 = TP2[TPs, on='tp']
# new uniquely mapped fraction
TP2[, numfrac := i.PE.uniq / PE.uniq]
# new mapping efficiency
TP2[, nmap.pe := (PE.uniq+PE.mult+i.PE.uniq+i.PE.mult)/PE.tot]
ddk = copy(TP2[, .(tp, sample, numfrac, map.pe, nmap.pe)])
plotBars(ddk, cols=c('numfrac'), id.vars='tp', xscale='Missing ratio') + ggtitle('Missing ratio per timepoint')
```
Values of numfrac larger than one mean that the alignment to the global ref aligns (uniquely) more reads than the uniquely aligned against the individual genome ref.



Just in case we want to know which timepoint / sample the spike is:
```{r}
flog.info('Timepoints for which numfrac > .5', TP2[numfrac > 1,], capture=T)
```
Using a threshold twice as big as in Tx to get a similar number of timepoints.
Not much correspondence to sample-tp that gave high number in transcriptome.


Summarise by sample:
```{r fig.width=8, fig.height=10}
ddl = ddk[, .(numfrac=sum(numfrac)/.N), by='sample']
setorder(ddl, numfrac)
plotBars(ddl, cols=c('numfrac'), id.vars='sample', ytext=6, xscale='Mean missing ratio') + ggtitle('Mean missing ratio per sample')
```
In these previous two figures, the ratio is the proportion of previously unmapped reads to original uniquely mapped reads when using the individual reference.
A value of .25 means that the newly identified reads are one fourth of previously identified (uniquely mapping).

Another way of looking at the missing species is by plotting the differential mapping efficiency, this will include the overall effect of reads multiply mapping as well.


```{r fig.width=8, fig.height=10}
ddj = TP2[, .(uniq=sum((PE.uniq+i.PE.uniq)/PE.tot)/.N, multi=sum((PE.mult+i.PE.mult)/PE.tot)/.N, nomap=sum(i.PE.noconc/PE.tot)/.N, D.mapeff=sum(nmap.pe-map.pe)/.N), by='sample']
setorder(ddj, nomap)
plotBars(ddj, cols=c('uniq','multi','nomap'), id.vars='sample', ytext=6, xscale='Fraction') + ggtitle('New mapping distribution after remap')
```

```{r fig.width=8, fig.height=10}
plotBars(ddj, cols=c('D.mapeff'), id.vars='sample', ytext=6, xscale='Mean fraction gain') + ggtitle('Mean delta mapping efficiency by sample')
```


## Detection of new species per individual

Decision on whether update the individual reference is based on a threshold on newly identified reads ratio. A value of .2 means we now uniquely map at least one fifth more than originally.
```{r}
nmap.thr = .5
ns2redo = ddl[numfrac >= nmap.thr, ]
flog.info('Using ratio %g to detect new species: %d samples exceed the threshold', nmap.thr, nrow(ns2redo))
ns2redo
```

For comparison, the mean delta efficiency and samples exceeding 20% gain in efficiency gain are:
```{r}
mapeff.thr = 0.20
ns2mapeff = ddj[D.mapeff >= mapeff.thr, ]
flog.info('Using a fractional gain in mapping efficiency of %g or more: %d samples exceed the threshold. Intersection: %d', 
          mapeff.thr, nrow(ns2mapeff), length(intersect(ns2redo$sample, ns2mapeff$sample)))
ns2mapeff
```

In order to detect which new species are there for the individual, we will extract the sequences information from the `.bam` file header and compare to the species list in the original reference definition file.
Then we need to count the new reads on the new species and filter the very low abundance ones.

We should update the individual references, rebuild and remap.  We will instead, as a first approximation, add these new reads to the previous and redo the count matrix.
The difference would be minimal, and expected only in the fraction of multiply mapped reads.

```{r, warning=FALSE}
# This part of the analysis requires the mapping of the HPC storage
stopifnot(dir.exists(dataDir3))
# List of bams
bamfiles = list.files(path=dataDir3, pattern='.*.bam', full.names=T)
flog.info('Found %d aligned BAM files', length(bamfiles))

procTimepBamPE <- function(file) {
  stopifnot(length(file) == 1)
  wh = setdiff(scanBamWhat(),  c('qual','seq','isize','mpos','mrnm'))
  tryCatch(
    gg = scanBam(file=file, param=ScanBamParam(flag=scanBamFlag(isUnmappedQuery=F, isProperPair=T), what=wh)),
    error=function(e) {flog.warn('Error in scanBam execution', e, capture=T); gg=NULL}
  )
  if(!is.null(gg)) {
    gx = as.data.table(gg[[1]])
    # Get read names for those marked as secondary (All are proper pairs, as per above filter)
    gs = gx[bitwAnd(flag, 256) == 256, qname]
    ns = length(gs)
    gs = unique(gs)
    # Get uniquely mapping: Those who have no secondary flag and read name not in list of secondaries
    gu = gx[(bitwAnd(flag, 256) == 0) & (!qname %in% gs), ]
    flog.info('File %s: %d alignments properly paired, %d are secondary pairs, %d pairs map uniquely (%d pair IDs are unique)', 
              basename(file), nrow(gx)/2, ns/2, nrow(gu)/2, length(unique(gu$qname)))
    # Get pair count by "chromosome"
    ds = gu[, .(file=basename(file), nr=.N), by='rname']
    setorder(ds, -nr)
    flog.info('File %s: %d contig sequences with unique mappings. %d contigs account for %g fraction of uniquely mapping pairs', 
              basename(file), nrow(ds), sum(.9 - cumsum(ds$nr)/nrow(gu) > 0), .9)
  } else {
    ds = NULL
  }
  return(ds)
}

seqsbam = NULL
cacheFile = 'seqsbam-gx.rds'
if(!file.exists(cacheFile)) {
  if(do.para) {
    seqsbam = bplapply(bamfiles, FUN=procTimepBamPE, BPPARAM=bpp)  
  } else {
    seqsbam = sapply(bamfiles, procTimepBamPE)
  }
  nm = sapply(seqsbam, function(z) {b = gsub('-sort.bam','',z[1, file]); z[, file := NULL]; return(b);} )
  names(seqsbam) = nm
  saveRDS(seqsbam, file=cacheFile)
  flog.info('Wrote cache file %s', cacheFile)
} else {
  seqsbam = readRDS(cacheFile)
  flog.info('Read cache file %s, contig sequence info for %d timepoints', cacheFile, length(seqsbam))
}
```

```{r}
nn = sapply(ns2redo$sample, function(z) {p=grep(z, bamfiles); names(p)=paste(z,seq(p),sep='.'); return(p)})
names(nn) = NULL
nn = unlist(nn)
bamfiles = bamfiles[nn]
flog.info('There are in total %d timepoint BAMs identified for the %d samples to process', length(nn), nrow(ns2redo))
```


Validity checks: All sequence levels should be same, but sequences not.  We test last using set intersection

```{r}
flog.info('"Chromosomal" sequences are the same for all timepoints: %s', 
          all(sapply(seqsbam, function(z) all.equal(levels(z$rname), levels(seqsbam[[1]]$rname)))))
flog.info('Lengths of sequence lists are the same: all:%s', all(sapply(seqsbam, function(z) nrow(z) == nrow(seqsbam[[1]]))))
```

Process references extracting list of chromosomal sequences.  We only get those references accounting for 0.8 of new uniquely mapping pairs in each timepoint, and then simplify to list each only once.
```{r}
nm = names(seqsbam)
snm = gsub('([A-Z0-9]+)-.*','\\1',nm)
allRefs = readRDS(file=paste0(refsDir, 'all-references.gff.rds'))

genomes4sample <- function(asamp, genoDir='') {
  aFile = paste0(genoDir, 'genomelist-', asamp, '.txt')
  ll = readLines(aFile)
  return(unique(gsub('^output = "([^.]+)\\.([0-9]+)_.*$', '\\1.\\2', ll[grep('^output =',ll)])))
}

for(kk in ns2redo$sample) {
  nn = grep(paste0('^',kk,'-'), names(seqsbam))
  g4s = genomes4sample(kk, genoDir=genoDir)
  topgeno = NULL
  for(nz in nn) {
    zz = seqsbam[[nz]]
    ns = sum(.8 - cumsum(zz$nr)/sum(zz$nr) > 0)
    xx = zz[1:ns,]
    thisgeno = unique(allRefs[xx, ncbi_genome, on=c(seqname='rname')])
    topgeno = union(topgeno, thisgeno)
    flog.info('Sample: %s: %d new refs, %d total', kk, length(thisgeno), length(topgeno))
  }
  nFile = paste0(genoDir, 'addgenolist-gx-', kk, '.txt')
  if(!file.exists(nFile)) {
    writeLines(topgeno, con=nFile)
    flog.info('Wrote new refs to %s', nFile)
  } else {
    flog.info('File exists: %s, skipping', nFile)
  }
}
```

```{r}
cacheFile2 = 'seqsbam.rds'
seqsbam_gx = seqsbam
stopifnot(file.exists(cacheFile2))
seqsbam_tx = readRDS(cacheFile2)
txff = gsub('addgenolist-([A-Z0-9]+).txt','\\1',basename(list.files(path=genoDir, pattern='addgenolist-[A-Z0-9]+.txt', full.names=T)))
flog.info('Samples listed in both Gx and Tx with missing species:', txff[which(txff %in% ns2redo$sample)], capture=T)
```
Not much of a coincidence.


```{r}
```

```{r}
```

```{r}
```

```{r}
```

```{r}
```

```{r}
```

```{r}
```

